pred3<-predict(fit3, type = "class",newdata = validation)
table3<-table(validation$solar_system_count,pred3)
accuracy3<-sum(diag(table3))/sum(table3)
print("Fit3 over")
#Bagging
fit4<-bagging(solar_system_count~.,data = train)
pred4<-predict(fit4, type = "class",newdata = validation)
table4<-table(validation$solar_system_count,pred4$class)
accuracy4<-sum(diag(table4))/sum(table4)
print("Fit4 over")
#Boosting
fit5<-boosting(solar_system_count~.,data = train)
pred5<-predict(fit5, type = "class",newdata = validation)
table5<-table(validation$solar_system_count,pred5$class)
accuracy5<-sum(diag(table5))/sum(table5)
print("Fit5 over")
#Support Vector Machines
fit6<-ksvm(solar_system_count~.,data = train)
pred6<-predict(fit6, newdata = validation)
table6<-table(validation$solar_system_count,pred6)
accuracy6<-sum(diag(table6))/sum(table6)
print("Fit6 over")
out[r,1] <- accuracy1
out[r,2] <- accuracy2
out[r,3] <- accuracy3
out[r,4] <- accuracy4
out[r,5] <- accuracy5
out[r,6] <- accuracy6
out[r,7] <- names( which.max(out) )
#To check the iteration number
print(r)
}
#cl <- parallel::makeCluster(2)
#doParallel::registerDoParallel(cl)
# replicate the process a number of times
R <- 100
out <- matrix(NA, R, 7)
colnames(out) <- c("ClassificationTree","LogisticRegression","RandomForest","Bagging","Boosting","Supportvector", "best")
out <- as.data.frame(out)
for ( r in 1:R ) {
#foreach(r =1:R) %dopar% {
#We will split the training data further into training and validation data
M<-nrow(trainingdata)
trainnum<-sample(1:M,size = 0.75*M)
valnum<-setdiff(1:M,trainnum)
train<-trainingdata[trainnum,]
validation<-trainingdata[valnum,]
# classification tree
fit1<-rpart(train$solar_system_count~.,data=train)
pred1<-predict(fit1, type = "class",newdata = validation)
table1<-table(validation$solar_system_count,pred1)
table1
accuracy1<-sum(diag(table1))/sum(table1)
print("Fit1 over")
#Logistic Regression
deepsolarSdval$solar_system_count<-recode(deepsolarSdval$solar_system_count,'low'=0,'high'=1)
trainLogisticR<-train
validationLogisticR<-validation
trainLogisticR$solar_system_count<-recode(trainLogisticR$solar_system_count,'low'=0,'high'=1)
validationLogisticR$solar_system_count<-recode(validationLogisticR$solar_system_count,'low'=0,'high'=1)
fit2<-glm(trainLogisticR$solar_system_count~.,data=trainLogisticR,family = "binomial")
summary(fit2)
#Prediction object is created using prediction function
predObj<-prediction(fitted(fit2),trainLogisticR$solar_system_count)
#Sensitivity and Specificity calculation for optimal threshold value
sens<-performance(predObj,"sens")
spec<-performance(predObj,"spec")
tau<-sens@x.values[[1]]
#Sum of Sensitivity and Specificity
sensSpec<-sens@y.values[[1]] + spec@y.values[[1]]
#Finding the maximum of Sum of Sensitivity and Specificity
best<-which.max(sensSpec)
pred2<-predict(fit2,type = "response",newdata = validationLogisticR)
#Classification for optimal threshold
pred2<-ifelse(pred2>tau[best],1,0)
table2<-table(validationLogisticR$solar_system_count,pred2)
accuracy2<-sum(diag(table2))/sum(table2)
print("Fit2 over")
#Random Forest
fit3<-randomForest(solar_system_count~.,data=train, importance=TRUE)
pred3<-predict(fit3, type = "class",newdata = validation)
table3<-table(validation$solar_system_count,pred3)
accuracy3<-sum(diag(table3))/sum(table3)
print("Fit3 over")
#Bagging
fit4<-bagging(solar_system_count~.,data = train)
pred4<-predict(fit4, type = "class",newdata = validation)
table4<-table(validation$solar_system_count,pred4$class)
accuracy4<-sum(diag(table4))/sum(table4)
print("Fit4 over")
#Boosting
fit5<-boosting(solar_system_count~.,data = train)
pred5<-predict(fit5, type = "class",newdata = validation)
table5<-table(validation$solar_system_count,pred5$class)
accuracy5<-sum(diag(table5))/sum(table5)
print("Fit5 over")
#Support Vector Machines
fit6<-ksvm(solar_system_count~.,data = train)
pred6<-predict(fit6, newdata = validation)
table6<-table(validation$solar_system_count,pred6)
accuracy6<-sum(diag(table6))/sum(table6)
print("Fit6 over")
out[r,1] <- accuracy1
out[r,2] <- accuracy2
out[r,3] <- accuracy3
out[r,4] <- accuracy4
out[r,5] <- accuracy5
out[r,6] <- accuracy6
out[r,7] <- names( which.max(out) )
#To check the iteration number
print(r)
}
names( which.max(out) )
names( which.max(out) )
detectCores()
library(foreach)
library(doParallel)
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
# replicate the process a number of times
R <- 2
out <- matrix(NA, R, 7)
colnames(out) <- c("ClassificationTree","LogisticRegression","RandomForest","Bagging","Boosting","Supportvector", "best")
out <- as.data.frame(out)
#for ( r in 1:R ) {
foreach(r =1:R) %dopar% {
library(dplyr)
library(mlbench)
library(rpart)
library(kernlab)
library(ROCR)
library(randomForest)
library(adabag)
library(nnet)
#We will split the training data further into training and validation data
M<-nrow(trainingdata)
trainnum<-sample(1:M,size = 0.75*M)
valnum<-setdiff(1:M,trainnum)
train<-trainingdata[trainnum,]
validation<-trainingdata[valnum,]
# classification tree
fit1<-rpart(train$solar_system_count~.,data=train)
pred1<-predict(fit1, type = "class",newdata = validation)
table1<-table(validation$solar_system_count,pred1)
table1
accuracy1<-sum(diag(table1))/sum(table1)
#print("Fit1 over")
#Logistic Regression
deepsolarSdval$solar_system_count<-recode(deepsolarSdval$solar_system_count,'low'=0,'high'=1)
trainLogisticR<-train
validationLogisticR<-validation
trainLogisticR$solar_system_count<-recode(trainLogisticR$solar_system_count,'low'=0,'high'=1)
validationLogisticR$solar_system_count<-recode(validationLogisticR$solar_system_count,'low'=0,'high'=1)
fit2<-glm(trainLogisticR$solar_system_count~.,data=trainLogisticR,family = "binomial")
summary(fit2)
#Prediction object is created using prediction function
predObj<-prediction(fitted(fit2),trainLogisticR$solar_system_count)
#Sensitivity and Specificity calculation for optimal threshold value
sens<-performance(predObj,"sens")
spec<-performance(predObj,"spec")
tau<-sens@x.values[[1]]
#Sum of Sensitivity and Specificity
sensSpec<-sens@y.values[[1]] + spec@y.values[[1]]
#Finding the maximum of Sum of Sensitivity and Specificity
best<-which.max(sensSpec)
pred2<-predict(fit2,type = "response",newdata = validationLogisticR)
#Classification for optimal threshold
pred2<-ifelse(pred2>tau[best],1,0)
table2<-table(validationLogisticR$solar_system_count,pred2)
accuracy2<-sum(diag(table2))/sum(table2)
#print("Fit2 over")
#Random Forest
fit3<-randomForest(solar_system_count~.,data=train, importance=TRUE)
pred3<-predict(fit3, type = "class",newdata = validation)
table3<-table(validation$solar_system_count,pred3)
accuracy3<-sum(diag(table3))/sum(table3)
#print("Fit3 over")
#Bagging
fit4<-bagging(solar_system_count~.,data = train)
pred4<-predict(fit4, type = "class",newdata = validation)
table4<-table(validation$solar_system_count,pred4$class)
accuracy4<-sum(diag(table4))/sum(table4)
#print("Fit4 over")
#Boosting
fit5<-boosting(solar_system_count~.,data = train)
pred5<-predict(fit5, type = "class",newdata = validation)
table5<-table(validation$solar_system_count,pred5$class)
accuracy5<-sum(diag(table5))/sum(table5)
#print("Fit5 over")
#Support Vector Machines
fit6<-ksvm(solar_system_count~.,data = train)
pred6<-predict(fit6, newdata = validation)
table6<-table(validation$solar_system_count,pred6)
accuracy6<-sum(diag(table6))/sum(table6)
#print("Fit6 over")
accuracytable <- c(ClassificationTree = accuracy1,LogisticRegression=accuracy2,RandomForest = accuracy3, Bagging=accuracy4, Boosting=accuracy5, Supportvector=accuracy6)
out[r,1] <- accuracy1
out[r,2] <- accuracy2
out[r,3] <- accuracy3
out[r,4] <- accuracy4
out[r,5] <- accuracy5
out[r,6] <- accuracy6
out[r,7] <- names( which.max(accuracytable) )
#To check the iteration number
print(r)
}
View(out)
parallel::stopCluster(cl)
out
library(foreach)
library(doParallel)
cl <- parallel::makeCluster(7)
doParallel::registerDoParallel(cl)
R<-4
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-0.49
}
parallel::stopCluster(cl)
cl <- parallel::makeCluster(7)
doParallel::registerDoParallel(cl)
R<-4
{
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(0.11,0.23,0.45,0.49)
}
parallel::stopCluster(cl)
}
xx
R<-4
{
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(0.11+r,0.23+r,0.45+r,0.49+r)
}
parallel::stopCluster(cl)
}
{
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(r,0.11+r,0.23+r,0.45+r,0.49+r)
}
parallel::stopCluster(cl)
}
{
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(r,0.11,0.23,0.45,0.49)
}
parallel::stopCluster(cl)
}
{
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(0.11,0.23,0.45,0.49)
}
parallel::stopCluster(cl)
}
cl <- parallel::makeCluster(7)
doParallel::registerDoParallel(cl)
R<-4
{
xx<-foreach(r =1:R,.combine = "c") %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(r,0.11+r,0.23+r,0.45+r,0.49+r)
}
parallel::stopCluster(cl)
}
xx
rm(xx,R,r)
cl <- parallel::makeCluster(7)
doParallel::registerDoParallel(cl)
R<-4
{
xx<-foreach(r =1:R,.combine = rbind) %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(r,0.11+r,0.23+r,0.45+r,0.49+r)
}
parallel::stopCluster(cl)
}
xx
cl <- parallel::makeCluster(7)
doParallel::registerDoParallel(cl)
R<-4
xx<-matrix(NA, R, 4)
colnames(xx)<-c("A","B","C","D")
{
xx<-foreach(r =1:R,.combine = rbind) %dopar% {
xx1<-0.89
xx2<-0.79
xx3<-0.69
xx4<-0.59
xx5<-c(r,0.11+r,0.23+r,0.45+r,0.49+r)
}
parallel::stopCluster(cl)
}
xx
xx[,1]
library(foreach)
library(doParallel)
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
# replicate the process a number of times
R <- 2
out <- matrix(NA, R, 7)
colnames(out) <- c("ClassificationTree","LogisticRegression","RandomForest","Bagging","Boosting","Supportvector", "best")
out <- as.data.frame(out)
#for ( r in 1:R ) {
foreach(r =1:R,.combine = rbind) %dopar% {
library(dplyr)
library(mlbench)
library(rpart)
library(kernlab)
library(ROCR)
library(randomForest)
library(adabag)
library(nnet)
#We will split the training data further into training and validation data
M<-nrow(trainingdata)
trainnum<-sample(1:M,size = 0.75*M)
valnum<-setdiff(1:M,trainnum)
train<-trainingdata[trainnum,]
validation<-trainingdata[valnum,]
# classification tree
fit1<-rpart(train$solar_system_count~.,data=train)
pred1<-predict(fit1, type = "class",newdata = validation)
table1<-table(validation$solar_system_count,pred1)
table1
accuracy1<-sum(diag(table1))/sum(table1)
#print("Fit1 over")
#Logistic Regression
deepsolarSdval$solar_system_count<-recode(deepsolarSdval$solar_system_count,'low'=0,'high'=1)
trainLogisticR<-train
validationLogisticR<-validation
trainLogisticR$solar_system_count<-recode(trainLogisticR$solar_system_count,'low'=0,'high'=1)
validationLogisticR$solar_system_count<-recode(validationLogisticR$solar_system_count,'low'=0,'high'=1)
fit2<-glm(trainLogisticR$solar_system_count~.,data=trainLogisticR,family = "binomial")
summary(fit2)
#Prediction object is created using prediction function
predObj<-prediction(fitted(fit2),trainLogisticR$solar_system_count)
#Sensitivity and Specificity calculation for optimal threshold value
sens<-performance(predObj,"sens")
spec<-performance(predObj,"spec")
tau<-sens@x.values[[1]]
#Sum of Sensitivity and Specificity
sensSpec<-sens@y.values[[1]] + spec@y.values[[1]]
#Finding the maximum of Sum of Sensitivity and Specificity
best<-which.max(sensSpec)
pred2<-predict(fit2,type = "response",newdata = validationLogisticR)
#Classification for optimal threshold
pred2<-ifelse(pred2>tau[best],1,0)
table2<-table(validationLogisticR$solar_system_count,pred2)
accuracy2<-sum(diag(table2))/sum(table2)
#print("Fit2 over")
#Random Forest
fit3<-randomForest(solar_system_count~.,data=train, importance=TRUE)
pred3<-predict(fit3, type = "class",newdata = validation)
table3<-table(validation$solar_system_count,pred3)
accuracy3<-sum(diag(table3))/sum(table3)
#print("Fit3 over")
#Bagging
fit4<-bagging(solar_system_count~.,data = train)
pred4<-predict(fit4, type = "class",newdata = validation)
table4<-table(validation$solar_system_count,pred4$class)
accuracy4<-sum(diag(table4))/sum(table4)
#print("Fit4 over")
#Boosting
fit5<-boosting(solar_system_count~.,data = train)
pred5<-predict(fit5, type = "class",newdata = validation)
table5<-table(validation$solar_system_count,pred5$class)
accuracy5<-sum(diag(table5))/sum(table5)
#print("Fit5 over")
#Support Vector Machines
fit6<-ksvm(solar_system_count~.,data = train)
pred6<-predict(fit6, newdata = validation)
table6<-table(validation$solar_system_count,pred6)
accuracy6<-sum(diag(table6))/sum(table6)
#print("Fit6 over")
accuracytable <- c(ClassificationTree = accuracy1,LogisticRegression=accuracy2,RandomForest = accuracy3, Bagging=accuracy4, Boosting=accuracy5, Supportvector=accuracy6)
out[r,1] <- accuracy1
out[r,2] <- accuracy2
out[r,3] <- accuracy3
out[r,4] <- accuracy4
out[r,5] <- accuracy5
out[r,6] <- accuracy6
out[r,7] <- names( which.max(accuracytable) )
bestaccuracy<-names( which.max(accuracytable) )
#To check the iteration number
#print(r)
parallelvalues<-c(accuracy1,accuracy2,accuracy3,accuracy4,accuracy5,accuracy6,bestaccuracy)
}
library(foreach)
library(doParallel)
cl <- parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
# replicate the process a number of times
R <- 2
out <- matrix(NA, R, 7)
colnames(out) <- c("ClassificationTree","LogisticRegression","RandomForest","Bagging","Boosting","Supportvector", "best")
out <- as.data.frame(out)
#for ( r in 1:R ) {
out<-foreach(r =1:R,.combine = rbind) %dopar% {
library(dplyr)
library(mlbench)
library(rpart)
library(kernlab)
library(ROCR)
library(randomForest)
library(adabag)
library(nnet)
#We will split the training data further into training and validation data
M<-nrow(trainingdata)
trainnum<-sample(1:M,size = 0.75*M)
valnum<-setdiff(1:M,trainnum)
train<-trainingdata[trainnum,]
validation<-trainingdata[valnum,]
# classification tree
fit1<-rpart(train$solar_system_count~.,data=train)
pred1<-predict(fit1, type = "class",newdata = validation)
table1<-table(validation$solar_system_count,pred1)
table1
accuracy1<-sum(diag(table1))/sum(table1)
#print("Fit1 over")
#Logistic Regression
deepsolarSdval$solar_system_count<-recode(deepsolarSdval$solar_system_count,'low'=0,'high'=1)
trainLogisticR<-train
validationLogisticR<-validation
trainLogisticR$solar_system_count<-recode(trainLogisticR$solar_system_count,'low'=0,'high'=1)
validationLogisticR$solar_system_count<-recode(validationLogisticR$solar_system_count,'low'=0,'high'=1)
fit2<-glm(trainLogisticR$solar_system_count~.,data=trainLogisticR,family = "binomial")
summary(fit2)
#Prediction object is created using prediction function
predObj<-prediction(fitted(fit2),trainLogisticR$solar_system_count)
#Sensitivity and Specificity calculation for optimal threshold value
sens<-performance(predObj,"sens")
spec<-performance(predObj,"spec")
tau<-sens@x.values[[1]]
#Sum of Sensitivity and Specificity
sensSpec<-sens@y.values[[1]] + spec@y.values[[1]]
#Finding the maximum of Sum of Sensitivity and Specificity
best<-which.max(sensSpec)
pred2<-predict(fit2,type = "response",newdata = validationLogisticR)
#Classification for optimal threshold
pred2<-ifelse(pred2>tau[best],1,0)
table2<-table(validationLogisticR$solar_system_count,pred2)
accuracy2<-sum(diag(table2))/sum(table2)
#print("Fit2 over")
#Random Forest
fit3<-randomForest(solar_system_count~.,data=train, importance=TRUE)
pred3<-predict(fit3, type = "class",newdata = validation)
table3<-table(validation$solar_system_count,pred3)
accuracy3<-sum(diag(table3))/sum(table3)
#print("Fit3 over")
#Bagging
fit4<-bagging(solar_system_count~.,data = train)
pred4<-predict(fit4, type = "class",newdata = validation)
table4<-table(validation$solar_system_count,pred4$class)
accuracy4<-sum(diag(table4))/sum(table4)
#print("Fit4 over")
#Boosting
fit5<-boosting(solar_system_count~.,data = train)
pred5<-predict(fit5, type = "class",newdata = validation)
table5<-table(validation$solar_system_count,pred5$class)
accuracy5<-sum(diag(table5))/sum(table5)
#print("Fit5 over")
#Support Vector Machines
fit6<-ksvm(solar_system_count~.,data = train)
pred6<-predict(fit6, newdata = validation)
table6<-table(validation$solar_system_count,pred6)
accuracy6<-sum(diag(table6))/sum(table6)
#print("Fit6 over")
accuracytable <- c(ClassificationTree = accuracy1,LogisticRegression=accuracy2,RandomForest = accuracy3, Bagging=accuracy4, Boosting=accuracy5, Supportvector=accuracy6)
out[r,1] <- accuracy1
out[r,2] <- accuracy2
out[r,3] <- accuracy3
out[r,4] <- accuracy4
out[r,5] <- accuracy5
out[r,6] <- accuracy6
out[r,7] <- names( which.max(accuracytable) )
bestaccuracy<-names( which.max(accuracytable) )
#To check the iteration number
#print(r)
parallelvalues<-c(accuracy1,accuracy2,accuracy3,accuracy4,accuracy5,accuracy6,bestaccuracy)
}
parallel::stopCluster(cl)
out
setwd("~/UCD/SML/Project")
